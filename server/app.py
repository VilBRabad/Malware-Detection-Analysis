from dotenv import load_dotenv
load_dotenv()

from flask import Flask, jsonify, request, session
from supabase import create_client
from flask_cors import CORS
from utils import *
import os
import bcrypt
import torch
import pickle
# from models.RNN_Model import MalwareDetector 
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import pandas as pd
import numpy as np
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import json
from sklearn.ensemble import RandomForestClassifier
from models.RNN_Model_def import MalwareDetector
from models.Logistic_Model_def import LogisticRegression
import joblib
import time
# from models.Feature_Extraction import getDF

app = Flask(__name__)
CORS(app)
app.secret_key = os.environ.get("SECRETE_KEY")

url = os.environ.get("SUPABASE_URL")
key = os.environ.get("SUPABASE_KEY")
supabase = create_client(url, key)


@app.route("/")
def home():
    return "Vilas"

#********************** User Auth ************************
@app.route("/sign-up", methods=['POST'])
def register():
    req = request.json
    print(req)
    try:
        if req:
            email = req.get("email")
            password = req.get("password")
            if email == "" or password == "":
                return jsonify({"status": 401, "error": "Email or password can not empty"})
            
            checkUser = supabase.table("users").select("*").eq("email", email).execute()
            if len(checkUser.data) != 0:
                return jsonify({"status": 401, "error": "Email id already exists!"})
            
            hashed = hashedPassword(password)
            # print(hashed)

            db_res = supabase.table("users").insert({"email": email, "password": hashed}).execute()
            if db_res:
                return jsonify({"status": 201, "message": "register successfully"})
            else:
                return jsonify({"status": 400, "error": "unable to register"}) 

    except Exception as err:
        return jsonify({"status": 500, "error": "Server Error!"})


@app.route("/sign-in", methods=['POST'])
def login():
    try:
        req = request.json
        if req:
            email = req.get("email")
            password = req.get("password")
            if email == "" or password == "":
                return jsonify({"status": 401, "error": "Email or password can not empty"})
            
            db_res = supabase.table("users").select("*").eq("email", email).execute()
            data = db_res.data
            if len(data) == 0:
                return jsonify({"status": 401, "error": "Wrong Credentials"})
            
            # print("Vilas", data[0]['password'])
            hased = data[0]['password']
            if CheckPassword(password, hased):
                print("VIlas", email)
                session['user'] = email
                return jsonify({"status": 201, "message": "login successfully", "user": email})
            else:
                return jsonify({"status": 400, "error": "Wrong Credentials"})
            
    except Exception as err:
        return jsonify({"status": 500, "error": "Server Error!"})


@app.route("/logout", methods=['POST'])
def logout():
    session.pop("user", None)
    return jsonify({"status": 201, "message": "Logout Successfully"})

@app.route("/is-login", methods=['POST'])
def isLogin():
    if "user" in session:
        user = session["user"]
        return jsonify({"status":200, "message": "user loged in", "user":user})
    return jsonify({"status":401, "error": "please login...."})

# total_obfuscated_methods = 0
# total_malware_methods = 0
# num_correct_test = 0

@app.route('/upload-file', methods=['POST'])
def uploadFile():
    try:
        csv_file = request.files['file']
        if csv_file.filename.endswith('.csv'):
            csv_file.save('uploaded_file.csv')

            original_df = pd.read_csv('uploaded_file.csv', sep=',', encoding='utf-8')
            original_df.shape

            #*************** Cleaning File *************************
            df = original_df.copy()
            df.shape

            def select_every_nth_row(df, n=1000):
                selected_rows = df.iloc[::n]
                return selected_rows

            selected_rows = select_every_nth_row(df, n=1000)

            columns_to_drop = ['pslist.nprocs64bit', 'handles.nport', 'svcscan.interactive_process_services']

            # Drop the specified columns
            df.drop(columns=columns_to_drop, inplace=True)

            df.fillna(method="ffill", inplace=True)  # Forward fill missing values
            df.drop_duplicates(inplace=True)

            df["Class"] = df["Class"].astype("category")

            df = pd.get_dummies(df, columns=["Class"], drop_first=True)

            total_methods = len(df) 

            #******************* Separate features and target *****************
            y = df["Class_Malware"]
            X = df.drop(columns=["Category", "Class_Malware"])

            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)


            # Feature extraction using t-SNE
            tsne = TSNE(n_components=2, perplexity=30, n_iter=300)
            X_tsne = tsne.fit_transform(X_scaled)

            X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(X_tsne, y.values, test_size=0.2, random_state=42)

            input_size = len(X_train[0])

            X_train_tensor = torch.from_numpy(X_train).float()
            X_test_tensor = torch.from_numpy(X_test).float()
            y_test_tensor = torch.from_numpy(y_test_encoded).long()
            y_train_tensor = torch.from_numpy(y_train_encoded).long()

            print("******** Check Point: 1")
            test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)
            print("******** Check Point: 1.2")
            dnn_metrices = DNN_model(test_dataset, input_size)
            print("******** Check Point: 1.3")
            logistic_metrices = Logistic_Model(X_test_tensor, y_test_encoded, input_size)
            print("******** Check Point: 1.4")
            random_forest_metrices = random_Forest_model(X_train, y_train_encoded, X_test, y_test_encoded)

            print("******** Check Point: 2")
            num_correct_test = dnn_metrices[1]
            total_obfuscated_methods = dnn_metrices[2]
            total_malware_methods = dnn_metrices[3]
            distributionOfMethods = getMethods(total_methods, total_obfuscated_methods, total_malware_methods)
            print("******** Check Point: 3")
            malwareDetValuse = malwareDetPercentage(num_correct_test, total_malware_methods)
            print("******** Check Point: 4")
            
            model_cal = {
                "DNN": dnn_metrices[0], 
                "LOG": logistic_metrices,
                "RFM": random_forest_metrices,
            }
            model_result = {
                "Dist": distributionOfMethods,
                "malwareDetPer": malwareDetValuse
            }
            data = {
                "model_cal": model_cal,
                "model_result": model_result
            }
            # for model_data in data.values():
            #     model_data['Confusion Matrix'] = model_data['Confusion Matrix'].tolist()

            print("******** Check Point: 5")
            print(data)
            # Convert the dictionary to JSON
            json_data = json.dumps(data)
            print(json_data)
            return jsonify(json_data)
        else:
            return jsonify({"status": 500, "error": 'not uploaded'})
    except Exception as err:
        print("Error: ", err)
        return jsonify({"status": 500, "error": "server error"})


def DNN_model(test_dataset, input_size):
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)

    hidden_size = 128
    output_size = 2
    model = MalwareDetector(input_size, hidden_size, output_size)

    # Load the model's parameters (state dictionary)
    model.load_state_dict(torch.load('dnn_pickel.pth'))

    correct = 0
    total = 0
    y_true = []
    y_pred = []

    total_obfuscated_methods = 0
    total_malware_methods = 0

    num_correct_test = 0
    num_samples_test = 0
    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            print("******** Check Point: 1.2.1")
            num_correct_test += (predicted == labels).sum().item()
            print("******** Check Point: 1.2.2")
            num_samples_test += labels.size(0)

            # Count obfuscated methods and malware methods in the current batch
            print("******** Check Point: 1.2.3")
            total_obfuscated_methods += torch.sum(labels).item()  # Assuming labels indicate obfuscated methods
            print("******** Check Point: 1.2.4")
            total_malware_methods += torch.sum(labels).item()  # Assuming labels indicate malware methods
            print("******** Check Point: 1.2.5")

            # Store true labels and predicted labels for evaluation
            y_true.extend(labels.cpu().numpy())
            y_pred.extend(predicted.cpu().numpy())

    # Calculate accuracy
    accuracy = 100 * correct / total

    # Calculate additional evaluation metrics
    precision = precision_score(y_true, y_pred, average=None)
    recall = recall_score(y_true, y_pred, average=None)
    f1 = f1_score(y_true, y_pred, average=None)
    conf_matrix = confusion_matrix(y_true, y_pred)

    dnn_metrices = {
        "Accuracy": accuracy,
        "Precision": precision[0],
        "Recall": recall[0],
        "F1 Score": f1[0],
        # "Confusion Matrix": conf_matrix
    }
    print("\n***************DNN*******************")
    print("Accuracy: ", accuracy)
    print("Precision: ", precision[0])
    print("Recall: ", recall[0])
    print("F1 Score: ", f1[0])
    print("Confusion Matrix: ", conf_matrix)

    return [dnn_metrices, num_correct_test, total_obfuscated_methods, total_malware_methods]


def Logistic_Model(X_test_tensor, y_test_encoded, input_size):
    output_size = 2
    output_size = 2
    model = LogisticRegression(input_size, output_size)

    # Load the model's parameters (state dictionary)
    model.load_state_dict(torch.load('logistic_regression_state.pth'))

    model.eval()
    with torch.no_grad():
        outputs = model(X_test_tensor)
        _, predicted = torch.max(outputs.data, 1)

        accuracy = accuracy_score(y_test_encoded, predicted)*100
        precision = precision_score(y_test_encoded, predicted)
        recall = recall_score(y_test_encoded, predicted)
        f1 = f1_score(y_test_encoded, predicted)
        conf_matrix = confusion_matrix(y_test_encoded, predicted)

    print("\n***************Logistic*******************")
    print("Accuracy: ", accuracy)
    print("Precision: ", precision)
    print("Recall: ", recall)
    print("F1 Score: ", f1)
    print("Confusion Matrix: ", conf_matrix)

    logistic_metrices = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1 Score": f1,
        # "Confusion Matrix": conf_matrix
    }
    return logistic_metrices


def random_Forest_model(X_train, y_train_encoded, X_test, y_test_encoded):

    rf_classifier = joblib.load('rfc_model.pkl')

    y_pred = rf_classifier.predict(X_test)

    accuracy = accuracy_score(y_test_encoded, y_pred)*100
    precision = precision_score(y_test_encoded, y_pred)
    recall = recall_score(y_test_encoded, y_pred)
    f1 = f1_score(y_test_encoded, y_pred)
    conf_matrix = confusion_matrix(y_test_encoded, y_pred)

    metrices = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1 Score": f1,
        # "Confusion Matrix": conf_matrix
    }
    return metrices


def getMethods(total_methods, total_obfuscated_methods, total_malware_methods):
    # Print the total number of methods, obfuscated methods, and malware methods
    print("Total Methods:", total_methods)
    print("Total Obfuscated Methods:", total_obfuscated_methods)
    print("Total Malware Methods:", total_malware_methods)

    # sizes = [max(0, total_obfuscated_methods), max(0, total_malware_methods), max(0, total_methods - total_obfuscated_methods)]
    # Data for the pie chart
    labels = ['Obfuscated Methods', 'Malware Methods', 'Non-Obfuscated Methods']
    # colors = ['lightcoral', 'lightskyblue', 'lightgreen']
    # explode = (0.1, 0, 0)  # explode the 1st slice (Obfuscated Methods)

    # Data for the bar graph
    categories = ['Total Methods', 'Obfuscated Methods', 'Malware Methods']
    values = [total_methods, total_obfuscated_methods, total_malware_methods]

    data = {
        "values": values,
        "labels": labels,
        "categories": categories
    }

    return data


def malwareDetPercentage(num_correct_test, total_malware_methods):
    total_detected_percentage = (num_correct_test / total_malware_methods) * 100
    # Define labels for the pie chart
    labels = ['Malware Detected', 'Malware Not Detected']

    # Calculate the number of malware not detected (false negatives)
    num_not_detected_malware = total_malware_methods - num_correct_test

    # Define sizes for the pie chart wedges
    sizes = [num_correct_test, num_not_detected_malware]

    # Define colors for the pie chart wedges
    colors = ['lightcoral', 'lightskyblue']

    data = {
        "labels": labels,
        "sizes": sizes
    }

    return data



@app.route('/progress', methods=['GET'])
def progress():
    # Simulate progress updates (replace this with your actual progress calculation)
    for i in range(1, 11):
        time.sleep(1)  # Simulate processing time
        progress = i * 10
        print("Progress:", progress)
        # Send progress updates to client
        return jsonify({"progress": progress})

if __name__ == '__main__':
    app.run(debug=True)