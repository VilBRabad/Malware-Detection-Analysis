import torch.nn as nn
import torch
import torch.nn.functional as F
from sklearn.model_selection import train_test_split
# from sklearn.metrics import roc_auc_score
import torch.optim as optim
from Feature_Extraction import X_tsne, y
# import pickle
from Logistic_Model_def import LogisticRegression

# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
# from sklearn.metrics import matthews_corrcoef, auc, precision_recall_curve, classification_report


def train_model(model, optimizer, criterion, X_train_tensor, y_train_tensor):
    # Training loop
    for epoch in range(10): #epochs = 10
        optimizer.zero_grad()
        outputs = model(X_train_tensor)
        loss = criterion(outputs, y_train_tensor)
        loss.backward()
        optimizer.step()


X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(X_tsne, y.values, test_size=0.2, random_state=42)

# Convert the data to PyTorch tensors
X_train_tensor = torch.from_numpy(X_train).float()
y_train_tensor = torch.from_numpy(y_train_encoded).long()
X_test_tensor = torch.from_numpy(X_test).float()
y_test_tensor = torch.from_numpy(y_test_encoded).long()

input_size = len(X_train[0])
hidden_size = 128
output_size = 2

model = LogisticRegression(input_size, output_size)
# Define optimizer and criterion
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

train_model(model, optimizer, criterion, X_train_tensor, y_train_tensor)

# Save the model's state dictionary to a file
torch.save(model.state_dict(), 'logistic_regression_state.pth')

# 2. Export the model to a pickle file
# with open('logistic_pickel.pkl', 'wb') as f:
#     pickle.dump(model, f)
