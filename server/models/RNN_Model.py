from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import roc_auc_score
import pickle

class MalwareDetector(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(MalwareDetector, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)
        self.fc3 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = x.unsqueeze(1)  # Add a time step dimension
        out = torch.relu(self.fc1(x))
        out = torch.relu(self.fc2(out))
        out, _ = self.rnn(out)
        out = self.fc3(out[:, -1, :])  # Get the last output of the RNN
        return out


from models.Feature_Extraction import X_tsne, y
X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(X_tsne, y.values, test_size=0.2, random_state=42)

# Convert the data to PyTorch tensors
X_train_tensor = torch.from_numpy(X_train).float()
y_train_tensor = torch.from_numpy(y_train_encoded).long()
X_test_tensor = torch.from_numpy(X_test).float()
y_test_tensor = torch.from_numpy(y_test_encoded).long()


input_size = len(X_train[0])
print("#$$$$$$$LEN: ", input_size)
hidden_size = 128
output_size = 2  # 2 classes: benign and malicious
model = MalwareDetector(input_size, hidden_size, output_size)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)


#***************************** TRAINNING LOOP ******************************

# Initialize variables to store metrics
train_losses = []
train_accuracies = []
train_auc_scores = []
test_losses = []
test_accuracies = []
test_auc_scores = []

train_loss_sum = 0.0
num_correct_train = 0
num_samples_train = 0
y_true_train = []
y_pred_train = []

# Define the number of epochs
epochs = 10

# Loop through epochs
for epoch in range(epochs):
    model.train()

    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # Calculate training loss
        train_loss_sum += loss.item() * inputs.size(0)

        # Calculate number of correct predictions and total samples in the current batch
        _, predicted_train = torch.max(outputs.data, 1)
        num_correct_train += (predicted_train == labels).sum().item()
        num_samples_train += labels.size(0)

        # Store true labels and predicted labels for AUC calculation
        y_true_train.extend(labels.cpu().numpy())
        y_pred_train.extend(predicted_train.cpu().numpy())

    # Calculate training accuracy
    train_accuracy = 100 * num_correct_train / num_samples_train
    train_losses.append(train_loss_sum / num_samples_train)
    train_accuracies.append(train_accuracy)

    # Calculate AUC score for training data
    train_auc = roc_auc_score(y_true_train, y_pred_train, average='weighted')
    train_auc_scores.append(train_auc)

    # Evaluate the model on the test set
    model.eval()
    test_loss_sum = 0.0
    num_correct_test = 0
    num_samples_test = 0
    y_true_test = []
    y_pred_test = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            test_loss_sum += loss.item() * inputs.size(0)

            # Calculate number of correct predictions and total samples in the current batch
            _, predicted_test = torch.max(outputs.data, 1)
            num_correct_test += (predicted_test == labels).sum().item()
            num_samples_test += labels.size(0)

            # Store true labels and predicted labels for AUC calculation
            y_true_test.extend(labels.cpu().numpy())
            y_pred_test.extend(predicted_test.cpu().numpy())

    # Calculate test accuracy
    test_accuracy = 100 * num_correct_test / num_samples_test
    test_losses.append(test_loss_sum / num_samples_test)
    test_accuracies.append(test_accuracy)

    # Calculate AUC score for test data
    test_auc = roc_auc_score(y_true_test, y_pred_test, average='weighted')
    test_auc_scores.append(test_auc)

    # Print epoch-wise metrics
    print(f"Epoch [{epoch+1}/{epochs}] - "
          f"Train Loss: {train_losses[-1]:.4f}, "
          f"Train Accuracy: {train_accuracy:.2f}%, "
          f"Train AUC: {train_auc:.4f}, "
          f"Test Loss: {test_losses[-1]:.4f}, "
          f"Test Accuracy: {test_accuracy:.2f}%, "
          f"Test AUC: {test_auc:.4f}")

print("Training finished.")


torch.save(model.state_dict(), 'dnn_pickel.pth')

# 2. Export the model to a pickle file
with open('dnn_pickel.pkl', 'wb') as f:
    pickle.dump(model, f)